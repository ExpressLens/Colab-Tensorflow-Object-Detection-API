{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use Tensorflow Object Detection API in google colab .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amin-Tgz/Tensorflow-Object-Detection-API-google-colab/blob/master/Use_Tensorflow_Object_Detection_API_in_google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j6EQlc_BaLff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Object Detection Demo\n",
        "\n",
        "\n",
        "Welcome to the object detection inference walkthrough! This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the installation instructions before you start."
      ]
    },
    {
      "metadata": {
        "id": "06k_uzcgaNan",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installing necessary packages to run Tensorflow-Object Detetion_API in colab\n",
        "\n",
        "* install protobuf and cython\n",
        "* clone tensoflow models github\n",
        "* build protobuf\n",
        "* at the end test installation, so you must see pass 13 test in a short time"
      ]
    },
    {
      "metadata": {
        "id": "t0S8oRXk9rYd",
        "colab_type": "code",
        "outputId": "0d6486d8-7eb6-4801-faaa-43fb1dbfd5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "#!pip install jupyter\n",
        "#!pip install matplotlib\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 76%\r\rReading package lists... 76%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "python-pil is already the newest version (5.1.0-1).\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-lxml is already the newest version (4.2.1-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.5)\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            ".W0223 05:51:06.879596 140336981501824 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "....................s\n",
            "----------------------------------------------------------------------\n",
            "Ran 22 tests in 0.121s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAvJ958NZS2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Imports\n",
        "\n",
        "\n",
        "* remove check tf version , by default last version installed on colab\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CMrf7zaT-WYP",
        "colab_type": "code",
        "outputId": "dc12db9d-b862-4615-a0db-f159bbf4312c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "print('tensorflow version = ',tf.__version__)\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version =  1.13.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MxaIKjzQbmbU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* change directory to use utils "
      ]
    },
    {
      "metadata": {
        "id": "Tnls8IfmDBOa",
        "colab_type": "code",
        "outputId": "bcab92e2-3f76-45b6-801a-73fe23ba7065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N5c42uNYD7hU",
        "colab_type": "code",
        "outputId": "93a415c5-5c8e-433d-d6fb-39212937367f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ./object_detection/\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6vzckSSVES_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r67837Y5ZcxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model preparation"
      ]
    },
    {
      "metadata": {
        "id": "KC5qgkPKZjs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Any model exported using the **export_inference_graph.py** tool can be loaded here simply by changing **PATH_TO_FROZEN_GRAPH** to point to a new *.pb file*.\n",
        "\n",
        "By default we use an \"**SSD with Mobilenet**\" model here. See the detection model zoo for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
      ]
    },
    {
      "metadata": {
        "id": "UlYCmqJucF3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### copy model name from model download link\n",
        "[Tensorflow detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p__Mse81cr9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Link of Models](https://drive.google.com/uc?export=view&id=1Xi6sEQzzT6k4H6dN7ICk-am0qoVfb3En)"
      ]
    },
    {
      "metadata": {
        "id": "F-UrbS9_b55v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What model to download.  (without .tar.gz)\n",
        "\n",
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n",
        "# MODEL_NAME = 'faster_rcnn_resnet101_ava_v2.1_2018_04_30'\n",
        "# MODEL_NAME = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-_G2G9IEWGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7rLIh83cI8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* download model"
      ]
    },
    {
      "metadata": {
        "id": "oHzwS9h_Edbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PJhW9eq6i04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* load model from graph ([what_is_a_tfgraph?](https://www.tensorflow.org/guide/graphs#what_is_a_tfgraph))"
      ]
    },
    {
      "metadata": {
        "id": "VbWCa5BqEgjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCpAf4IQZ2Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Loading label map\n",
        "\n",
        "Label maps map indices to **category names**, so that when our convolution network predicts 5, we know that this corresponds to airplane. Here we use internal utility functions, but anything that returns a **dictionary mapping integers to appropriate string labels **would be fine\n",
        "\n",
        "* by default use mscoco_label_map.pbtxt for coco dataset*\n"
      ]
    },
    {
      "metadata": {
        "id": "oMGrLiPJEig4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM0BmzJZ7QfE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* define function that load image as np.array"
      ]
    },
    {
      "metadata": {
        "id": "v84EYXqhElns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8MqJ1whaCLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Detection phase"
      ]
    },
    {
      "metadata": {
        "id": "LERLzrwplp-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### upload image to test_image folder\n",
        "**Go to  ./models/research/object_detection/             directory  -->  right-click on test_images -->  upload**"
      ]
    },
    {
      "metadata": {
        "id": "fk9tr9ob5eNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![test_images](https://drive.google.com/uc?export=view&id=1PFYDd9yceM_a0QkylbJIk6dgo1xCLO_8)"
      ]
    },
    {
      "metadata": {
        "id": "jQxx11OmFox7",
        "colab_type": "code",
        "outputId": "bd352ff9-6893-43f5-ab3a-4fe45d10f731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "print('\\nyou must see your uploaded images here\\n')\n",
        "!ls ./test_images/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "\n",
            "you must see your uploaded images here\n",
            "\n",
            "image1.jpg  image2.jpg\timage_info.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5NpO41TzBUSV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* I add this section to read all jpg image in test_image folder"
      ]
    },
    {
      "metadata": {
        "id": "ahNqgt1BABrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "TEST_IMAGE_PATHS = []\n",
        "for filename in glob.iglob('./test_images/*.jpg', recursive=True):\n",
        "    TEST_IMAGE_PATHS.append(filename)\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDaadPuQBTti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* this code just read pictures that have 'image' at the first of their name so i comment it & and use above code!"
      ]
    },
    {
      "metadata": {
        "id": "-822uD6fEoVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "#PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
        "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(3, 4) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "#IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoVDm0ZrCFMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "access ouput of model graph by operation name [get-a-tensorflow-tensor-by-name](https://www.aiworkbox.com/lessons/get-a-tensorflow-tensor-by-name)"
      ]
    },
    {
      "metadata": {
        "id": "DDcZR-zGEsE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIIqgI9AmqEM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### A for loop that read all images in test_images path and feed into the network then show results"
      ]
    },
    {
      "metadata": {
        "id": "HwlzZer9Eunc",
        "colab_type": "code",
        "outputId": "2d6ef555-ffcb-489d-bdb5-d715e86a5310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "cell_type": "code",
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=4)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n",
        "  plt.grid(False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAHCCAYAAAAKOMR6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naDJhXPRIsiznEwpnSEbwHYzLEdH1xL6DlP1ljJGmXVBW2S94H