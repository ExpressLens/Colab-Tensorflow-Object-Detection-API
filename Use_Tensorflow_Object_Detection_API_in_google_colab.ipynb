{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use Tensorflow Object Detection API in google colab .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amin-Tgz/Tensorflow-Object-Detection-API-google-colab/blob/master/Use_Tensorflow_Object_Detection_API_in_google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j6EQlc_BaLff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Object Detection Demo\n",
        "\n",
        "\n",
        "Welcome to the object detection inference walkthrough! This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the installation instructions before you start."
      ]
    },
    {
      "metadata": {
        "id": "06k_uzcgaNan",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installing necessary packages to run Tensorflow-Object Detetion_API in colab\n",
        "\n",
        "* install protobuf and cython\n",
        "* clone tensoflow models github\n",
        "* build protobuf\n",
        "* at the end test installation, so you must see pass 13 test in a short time"
      ]
    },
    {
      "metadata": {
        "id": "t0S8oRXk9rYd",
        "colab_type": "code",
        "outputId": "0d6486d8-7eb6-4801-faaa-43fb1dbfd5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "#!pip install jupyter\n",
        "#!pip install matplotlib\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 76%\r\rReading package lists... 76%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "python-pil is already the newest version (5.1.0-1).\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-lxml is already the newest version (4.2.1-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.5)\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            ".W0223 05:51:06.879596 140336981501824 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "....................s\n",
            "----------------------------------------------------------------------\n",
            "Ran 22 tests in 0.121s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAvJ958NZS2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Imports\n",
        "\n",
        "\n",
        "* remove check tf version , by default last version installed on colab\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CMrf7zaT-WYP",
        "colab_type": "code",
        "outputId": "dc12db9d-b862-4615-a0db-f159bbf4312c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "print('tensorflow version = ',tf.__version__)\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version =  1.13.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MxaIKjzQbmbU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* change directory to use utils "
      ]
    },
    {
      "metadata": {
        "id": "Tnls8IfmDBOa",
        "colab_type": "code",
        "outputId": "bcab92e2-3f76-45b6-801a-73fe23ba7065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N5c42uNYD7hU",
        "colab_type": "code",
        "outputId": "93a415c5-5c8e-433d-d6fb-39212937367f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ./object_detection/\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6vzckSSVES_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r67837Y5ZcxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model preparation"
      ]
    },
    {
      "metadata": {
        "id": "KC5qgkPKZjs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Any model exported using the **export_inference_graph.py** tool can be loaded here simply by changing **PATH_TO_FROZEN_GRAPH** to point to a new *.pb file*.\n",
        "\n",
        "By default we use an \"**SSD with Mobilenet**\" model here. See the detection model zoo for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
      ]
    },
    {
      "metadata": {
        "id": "UlYCmqJucF3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### copy model name from model download link\n",
        "[Tensorflow detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p__Mse81cr9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Link of Models](https://drive.google.com/uc?export=view&id=1Xi6sEQzzT6k4H6dN7ICk-am0qoVfb3En)"
      ]
    },
    {
      "metadata": {
        "id": "F-UrbS9_b55v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What model to download.  (without .tar.gz)\n",
        "\n",
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n",
        "# MODEL_NAME = 'faster_rcnn_resnet101_ava_v2.1_2018_04_30'\n",
        "# MODEL_NAME = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-_G2G9IEWGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7rLIh83cI8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* download model"
      ]
    },
    {
      "metadata": {
        "id": "oHzwS9h_Edbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PJhW9eq6i04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* load model from graph ([what_is_a_tfgraph?](https://www.tensorflow.org/guide/graphs#what_is_a_tfgraph))"
      ]
    },
    {
      "metadata": {
        "id": "VbWCa5BqEgjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCpAf4IQZ2Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Loading label map\n",
        "\n",
        "Label maps map indices to **category names**, so that when our convolution network predicts 5, we know that this corresponds to airplane. Here we use internal utility functions, but anything that returns a **dictionary mapping integers to appropriate string labels **would be fine\n",
        "\n",
        "* by default use mscoco_label_map.pbtxt for coco dataset*\n"
      ]
    },
    {
      "metadata": {
        "id": "oMGrLiPJEig4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM0BmzJZ7QfE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* define function that load image as np.array"
      ]
    },
    {
      "metadata": {
        "id": "v84EYXqhElns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8MqJ1whaCLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Detection phase"
      ]
    },
    {
      "metadata": {
        "id": "LERLzrwplp-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### upload image to test_image folder\n",
        "**Go to  ./models/research/object_detection/             directory  -->  right-click on test_images -->  upload**"
      ]
    },
    {
      "metadata": {
        "id": "fk9tr9ob5eNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![test_images](https://drive.google.com/uc?export=view&id=1PFYDd9yceM_a0QkylbJIk6dgo1xCLO_8)"
      ]
    },
    {
      "metadata": {
        "id": "jQxx11OmFox7",
        "colab_type": "code",
        "outputId": "bd352ff9-6893-43f5-ab3a-4fe45d10f731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "print('\\nyou must see your uploaded images here\\n')\n",
        "!ls ./test_images/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "\n",
            "you must see your uploaded images here\n",
            "\n",
            "image1.jpg  image2.jpg\timage_info.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5NpO41TzBUSV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* I add this section to read all jpg image in test_image folder"
      ]
    },
    {
      "metadata": {
        "id": "ahNqgt1BABrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "TEST_IMAGE_PATHS = []\n",
        "for filename in glob.iglob('./test_images/*.jpg', recursive=True):\n",
        "    TEST_IMAGE_PATHS.append(filename)\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDaadPuQBTti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* this code just read pictures that have 'image' at the first of their name so i comment it & and use above code!"
      ]
    },
    {
      "metadata": {
        "id": "-822uD6fEoVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "#PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
        "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(3, 4) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "#IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoVDm0ZrCFMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "access ouput of model graph by operation name [get-a-tensorflow-tensor-by-name](https://www.aiworkbox.com/lessons/get-a-tensorflow-tensor-by-name)"
      ]
    },
    {
      "metadata": {
        "id": "DDcZR-zGEsE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\