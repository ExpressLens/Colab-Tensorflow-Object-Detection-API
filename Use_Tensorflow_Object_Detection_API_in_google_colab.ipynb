{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use Tensorflow Object Detection API in google colab .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amin-Tgz/Tensorflow-Object-Detection-API-google-colab/blob/master/Use_Tensorflow_Object_Detection_API_in_google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j6EQlc_BaLff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Object Detection Demo\n",
        "\n",
        "\n",
        "Welcome to the object detection inference walkthrough! This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the installation instructions before you start."
      ]
    },
    {
      "metadata": {
        "id": "06k_uzcgaNan",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installing necessary packages to run Tensorflow-Object Detetion_API in colab\n",
        "\n",
        "* install protobuf and cython\n",
        "* clone tensoflow models github\n",
        "* build protobuf\n",
        "* at the end test installation, so you must see pass 13 test in a short time"
      ]
    },
    {
      "metadata": {
        "id": "t0S8oRXk9rYd",
        "colab_type": "code",
        "outputId": "0d6486d8-7eb6-4801-faaa-43fb1dbfd5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "#!pip install jupyter\n",
        "#!pip install matplotlib\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 8%\r\rReading package lists... 76%\r\rReading package lists... 76%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 90%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "python-pil is already the newest version (5.1.0-1).\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-lxml is already the newest version (4.2.1-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.5)\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            ".W0223 05:51:06.879596 140336981501824 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "....................s\n",
            "----------------------------------------------------------------------\n",
            "Ran 22 tests in 0.121s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAvJ958NZS2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Imports\n",
        "\n",
        "\n",
        "* remove check tf version , by default last version installed on colab\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CMrf7zaT-WYP",
        "colab_type": "code",
        "outputId": "dc12db9d-b862-4615-a0db-f159bbf4312c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "print('tensorflow version = ',tf.__version__)\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version =  1.13.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MxaIKjzQbmbU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* change directory to use utils "
      ]
    },
    {
      "metadata": {
        "id": "Tnls8IfmDBOa",
        "colab_type": "code",
        "outputId": "bcab92e2-3f76-45b6-801a-73fe23ba7065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N5c42uNYD7hU",
        "colab_type": "code",
        "outputId": "93a415c5-5c8e-433d-d6fb-39212937367f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ./object_detection/\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6vzckSSVES_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r67837Y5ZcxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model preparation"
      ]
    },
    {
      "metadata": {
        "id": "KC5qgkPKZjs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Any model exported using the **export_inference_graph.py** tool can be loaded here simply by changing **PATH_TO_FROZEN_GRAPH** to point to a new *.pb file*.\n",
        "\n",
        "By default we use an \"**SSD with Mobilenet**\" model here. See the detection model zoo for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
      ]
    },
    {
      "metadata": {
        "id": "UlYCmqJucF3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### copy model name from model download link\n",
        "[Tensorflow detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p__Mse81cr9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Link of Models](https://drive.google.com/uc?export=view&id=1Xi6sEQzzT6k4H6dN7ICk-am0qoVfb3En)"
      ]
    },
    {
      "metadata": {
        "id": "F-UrbS9_b55v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What model to download.  (without .tar.gz)\n",
        "\n",
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n",
        "# MODEL_NAME = 'faster_rcnn_resnet101_ava_v2.1_2018_04_30'\n",
        "# MODEL_NAME = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-_G2G9IEWGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7rLIh83cI8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* download model"
      ]
    },
    {
      "metadata": {
        "id": "oHzwS9h_Edbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PJhW9eq6i04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* load model from graph ([what_is_a_tfgraph?](https://www.tensorflow.org/guide/graphs#what_is_a_tfgraph))"
      ]
    },
    {
      "metadata": {
        "id": "VbWCa5BqEgjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCpAf4IQZ2Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Loading label map\n",
        "\n",
        "Label maps map indices to **category names**, so that when our convolution network predicts 5, we know that this corresponds to airplane. Here we use internal utility functions, but anything that returns a **dictionary mapping integers to appropriate string labels **would be fine\n",
        "\n",
        "* by default use mscoco_label_map.pbtxt for coco dataset*\n"
      ]
    },
    {
      "metadata": {
        "id": "oMGrLiPJEig4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM0BmzJZ7QfE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* define function that load image as np.array"
      ]
    },
    {
      "metadata": {
        "id": "v84EYXqhElns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8MqJ1whaCLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Detection phase"
      ]
    },
    {
      "metadata": {
        "id": "LERLzrwplp-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### upload image to test_image folder\n",
        "**Go to  ./models/research/object_detection/             directory  -->  right-click on test_images -->  upload**"
      ]
    },
    {
      "metadata": {
        "id": "fk9tr9ob5eNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![test_images](https://drive.google.com/uc?export=view&id=1PFYDd9yceM_a0QkylbJIk6dgo1xCLO_8)"
      ]
    },
    {
      "metadata": {
        "id": "jQxx11OmFox7",
        "colab_type": "code",
        "outputId": "bd352ff9-6893-43f5-ab3a-4fe45d10f731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "print('\\nyou must see your uploaded images here\\n')\n",
        "!ls ./test_images/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "\n",
            "you must see your uploaded images here\n",
            "\n",
            "image1.jpg  image2.jpg\timage_info.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5NpO41TzBUSV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* I add this section to read all jpg image in test_image folder"
      ]
    },
    {
      "metadata": {
        "id": "ahNqgt1BABrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "TEST_IMAGE_PATHS = []\n",
        "for filename in glob.iglob('./test_images/*.jpg', recursive=True):\n",
        "    TEST_IMAGE_PATHS.append(filename)\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDaadPuQBTti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* this code just read pictures that have 'image' at the first of their name so i comment it & and use above code!"
      ]
    },
    {
      "metadata": {
        "id": "-822uD6fEoVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "#PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
        "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(3, 4) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "#IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoVDm0ZrCFMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "access ouput of model graph by operation name [get-a-tensorflow-tensor-by-name](https://www.aiworkbox.com/lessons/get-a-tensorflow-tensor-by-name)"
      ]
    },
    {
      "metadata": {
        "id": "DDcZR-zGEsE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIIqgI9AmqEM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### A for loop that read all images in test_images path and feed into the network then show results"
      ]
    },
    {
      "metadata": {
        "id": "HwlzZer9Eunc",
        "colab_type": "code",
        "outputId": "2d6ef555-ffcb-489d-bdb5-d715e86a5310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "cell_type": "code",
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=4)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n",
        "  plt.grid(False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAHCCAYAAAAKOMR6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7/Lbv/vbHN+5z/P37xL6LQ/fOudqNXJ4+gwXu8Q4nPPg5Jil